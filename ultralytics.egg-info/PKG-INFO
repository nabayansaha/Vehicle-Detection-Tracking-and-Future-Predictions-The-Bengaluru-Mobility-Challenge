Metadata-Version: 2.1
Name: ultralytics
Version: 8.1.34
Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.
Author: Glenn Jocher, Ayush Chaurasia, Jing Qiu
Maintainer: Glenn Jocher, Ayush Chaurasia, Jing Qiu
License: AGPL-3.0
Project-URL: Bug Reports, https://github.com/ultralytics/ultralytics/issues
Project-URL: Funding, https://ultralytics.com
Project-URL: Source, https://github.com/ultralytics/ultralytics/
Keywords: machine-learning,deep-learning,computer-vision,ML,DL,AI,YOLO,YOLOv3,YOLOv5,YOLOv8,HUB,Ultralytics
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Image Recognition
Classifier: Operating System :: POSIX :: Linux
Classifier: Operating System :: MacOS
Classifier: Operating System :: Microsoft :: Windows
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: matplotlib>=3.3.0
Requires-Dist: opencv-python>=4.6.0
Requires-Dist: pillow>=7.1.2
Requires-Dist: pyyaml>=5.3.1
Requires-Dist: requests>=2.23.0
Requires-Dist: scipy>=1.4.1
Requires-Dist: torch>=1.8.0
Requires-Dist: torchvision>=0.9.0
Requires-Dist: tqdm>=4.64.0
Requires-Dist: psutil
Requires-Dist: py-cpuinfo
Requires-Dist: thop>=0.1.1
Requires-Dist: pandas>=1.1.4
Requires-Dist: seaborn>=0.11.0
Provides-Extra: dev
Requires-Dist: ipython; extra == "dev"
Requires-Dist: check-manifest; extra == "dev"
Requires-Dist: pre-commit; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pytest-cov; extra == "dev"
Requires-Dist: coverage[toml]; extra == "dev"
Requires-Dist: mkdocs-material>=9.5.9; extra == "dev"
Requires-Dist: mkdocstrings[python]; extra == "dev"
Requires-Dist: mkdocs-jupyter; extra == "dev"
Requires-Dist: mkdocs-redirects; extra == "dev"
Requires-Dist: mkdocs-ultralytics-plugin>=0.0.44; extra == "dev"
Provides-Extra: export
Requires-Dist: onnx>=1.12.0; extra == "export"
Requires-Dist: coremltools>=7.0; (platform_system != "Windows" and python_version <= "3.11") and extra == "export"
Requires-Dist: openvino>=2024.0.0; extra == "export"
Requires-Dist: tensorflow<=2.13.1; python_version <= "3.11" and extra == "export"
Requires-Dist: tensorflowjs>=3.9.0; python_version <= "3.11" and extra == "export"
Provides-Extra: explorer
Requires-Dist: lancedb; extra == "explorer"
Requires-Dist: duckdb<=0.9.2; extra == "explorer"
Requires-Dist: streamlit; extra == "explorer"
Provides-Extra: logging
Requires-Dist: comet; extra == "logging"
Requires-Dist: tensorboard>=2.13.0; extra == "logging"
Requires-Dist: dvclive>=2.12.0; extra == "logging"
Provides-Extra: extra
Requires-Dist: hub-sdk>=0.0.5; extra == "extra"
Requires-Dist: ipython; extra == "extra"
Requires-Dist: albumentations>=1.0.3; extra == "extra"
Requires-Dist: pycocotools>=2.0.7; extra == "extra"

# Vehicle Detection and Tracking Project

This project utilizes a YOLOv10 model for vehicle detection, Kalman filtering for object tracking, and ARIMA forecasting for future vehicle count predictions. The primary objective is to detect, classify, and track vehicles in video feeds, and to provide both real-time and future predictions for vehicle counts based on different turning patterns.

## Project Structure
app.py: This is the main script that handles video processing, vehicle detection, tracking, and counting using YOLOv10 and Kalman filtering. It reads input from a JSON file specifying camera IDs and video paths, and outputs the detected counts to another JSON file.

generate_json.py: This script handles post-processing and generation of the final output JSON file. It formats the detected and predicted vehicle counts according to the specified output format.

best (1).pt: The pre-trained YOLOv10 model file used for vehicle detection.

yolov10n.pt: An alternative or backup model file for YOLOv10. Ensure that the models are accessible and properly loaded during inference.

Areas Folder: Contains configuration files or area definitions for the regions of interest in each camera view. These are used to define turning patterns.

camera Folder: Contains configuration details or mapping of cameras to their respective area definitions.

Videos Folder: Directory where input videos are stored. This is mounted to the Docker container during runtime.

Output Folder: Directory where output JSON files are stored. This is also mounted to the Docker container during runtime.

requirements.txt: Lists all the Python libraries and their versions required for running the project.

## System Requirements
To run this project effectively, the following hardware specifications are recommended:

CPU: Core i9 or equivalent
GPU: NVIDIA RTX 4090
RAM: 64GB
Storage: At least 500GB available space
Operating System: Compatible with both Linux and Windows environments (Docker required)

## Software Requirements
Docker: Ensure Docker is installed and running on your machine. You can download Docker from Docker's official website.
Python 3.9: The environment is set up using Python 3.9. Python packages are managed using a requirements.txt file.

## Setup Instructions

### 1. Build Docker Image
To build the Docker image for this project, navigate to the project directory and run the following command:
docker build -t vehicle_detection_image .

### 2. Run the Docker Container
The project requires input in the form of a JSON file specifying the camera ID and paths to the video files. Here is how you can run the Docker container:
docker run --rm --runtime=nvidia --gpus all \
  -v D:/Work_Space/vehicle_detection_project/Videos:/app/Videos \
  -v D:/Work_Space/vehicle_detection_project/Output:/app/Output \
  vehicle_detection_image:latest python3 app.py input_file.json output_file.json
In the command above:

--rm: Automatically remove the container once the command completes.
--runtime=nvidia --gpus all: Enable GPU acceleration using NVIDIA GPUs.
-v D:/Work_Space/vehicle_detection_project/Videos:/app/Videos: Mounts the host directory containing input videos to the container.
-v D:/Work_Space/vehicle_detection_project/Output:/app/Output: Mounts the output directory to store results.
vehicle_detection_image:latest: Name and tag of the Docker image.
python3 app.py input_file.json output_file.json: Command to run inside the container, where input_file.json specifies the camera ID and video paths, and output_file.json is the output file name.

### 3. Input JSON Format
The input JSON file should be structured as follows:
{
  "Cam_ID": {
    "Vid_1": "/app/Videos/video1.mp4",
    "Vid_2": "/app/Videos/video2.mp4"
  }
}
Cam_ID: Identifier for the camera.
Vid_1 and Vid_2: Paths to the video files to be processed.

### 4. Output
The output will be saved as Counts.json in the Output directory. The format of the JSON file will be:
{
  "Cam_ID": {
    "Cumulative Counts": {
      "Turning_Pattern": {
        "Bicycle": 0,
        "Bus": 0,
        "Car": 0,
        "LCV": 0,
        "Three Wheeler": 0,
        "Truck": 0,
        "Two Wheeler": 0
      },
      ...
    },
    "Predicted Counts": {
      "Turning_Pattern": {
        "Bicycle": 0,
        "Bus": 0,
        "Car": 0,
        "LCV": 0,
        "Three Wheeler": 0,
        "Truck": 0,
        "Two Wheeler": 0
      },
      ...
    }
  }
}

## Files and Scripts

app.py: Main application script to run vehicle detection, tracking, and counting.
generate_json.py: Script for generating the output JSON file with cumulative and predicted counts.
requirements.txt: Lists Python dependencies, such as torch, opencv-python, scikit-learn, and others required for the project.
best (1).pt: Pre-trained YOLOv10 model file used for vehicle detection.
yolov10n.pt: Alternative YOLOv10 model file.
README.md: This readme file provides setup and usage instructions.

## Open Source Models Used
YOLOv10: This project uses the YOLOv10 model for vehicle detection. The model weights are stored in .pt files (best (1).pt and yolov10n.pt). More information about YOLOv10 can be found on its official repository.

## References
YOLOv10: Ultralytics YOLOv10 model for object detection, referenced from the official Ultralytics GitHub repository.
ARIMA: ARIMA model used for time series forecasting of vehicle counts.
Kalman Filtering: Used for tracking and estimating the trajectories of detected vehicles.

## Notes
Ensure that the Docker environment is set up with GPU support.
Modify the input_file.json with the appropriate video paths before running the container.
The paths in the JSON should be correctly mapped to the directories mounted in the Docker container.
This project has been tested to work on a system with the recommended specifications mentioned above.
